{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f410fd87-17e8-487d-8729-85032653e573",
   "metadata": {},
   "source": [
    "# Live Session: COMPUTER VISION\n",
    "**AI Track Batch 5 (2023)**\n",
    "<br>Prepared by **Nicholas Dominic**\n",
    "<br>Startup Campus, Indonesia"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63bfff58-912d-489a-a313-f1bf3b0056f9",
   "metadata": {},
   "source": [
    "### Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e488025-b8e4-4507-9f5a-9e6e2085f8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2, numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from skimage.io import imread\n",
    "from skimage.measure import block_reduce"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9acc867-e07c-47f6-a9dc-a98477f4d692",
   "metadata": {},
   "source": [
    "### UDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09961e00-2791-4b20-bddd-4cef45f38f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_comparison(img1, title1, img2, title2):\n",
    "    cmap1 = \"gray\" if len(img1.shape) == 2 else None\n",
    "    cmap2 = \"gray\" if len(img2.shape) == 2 else None\n",
    "    \n",
    "    fig = plt.figure(figsize=(10, 5))\n",
    "    a = fig.add_subplot(121)\n",
    "    plt.title(title1)\n",
    "    plt.imshow(img1, cmap=cmap1)\n",
    "\n",
    "    b = fig.add_subplot(122)\n",
    "    plt.title(title2)\n",
    "    plt.imshow(img2, cmap=cmap2)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dba06a4-b95a-4097-9469-96d2c09941c6",
   "metadata": {},
   "source": [
    "### 0. Load image directly from URI using Scikit-image (Skimage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d32751b2-e077-4748-baba-8a0d75f325df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217193d5-b7d8-423b-ae60-74869f585af7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bba19e2-ecc9-4189-9f6d-970842445793",
   "metadata": {},
   "source": [
    "### 1. Channel Conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff73682-ba2e-456a-821e-5bf317d657b7",
   "metadata": {},
   "source": [
    "* To grayscale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8861f5e-44e7-4eee-8273-010efe20cf61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5a6991e1-e471-4587-b431-b9315e71399b",
   "metadata": {},
   "source": [
    "* To binary\n",
    "\n",
    "`REMEMBER` For binary conversion, the image should be in **grayscale** format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e55c52-a562-4726-b106-70e10e6ed1cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "66d0574b-4487-4274-8011-66f7808a797d",
   "metadata": {},
   "source": [
    "### 2. Image Enhancement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63bd9ba-d564-4c2c-8a47-edf9290a6642",
   "metadata": {},
   "source": [
    "* Increase brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f49406-9244-4b48-8128-5f0847a23533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def increase_brightness(img, value=30):\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "    h, s, v = cv2.split(hsv) # HSV = Hue, Saturation (gray), Value (brightness)\n",
    "\n",
    "    lim = 255 - value\n",
    "    v[v > lim] = 255\n",
    "    v[v <= lim] += value\n",
    "\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    return cv2.cvtColor(final_hsv, cv2.COLOR_HSV2BGR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752a3a1a-f052-484c-bee9-b9b3572f2f77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f08a97d-af92-4ec8-afd0-3f71bbbca249",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86a96ba0-17a8-4ddb-a929-ca1e9a578335",
   "metadata": {},
   "source": [
    "* Histogram for RGB Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70ab510-25ce-4f4f-a739-4d37e6652944",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2e10a2b-3238-4039-867f-c59070bd623b",
   "metadata": {},
   "source": [
    "* Histogram for Grayscaled Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420432d9-3ff4-410e-87a6-fd37db0c9cae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b93c74f1-9ce4-4eaa-b64c-4a2a7dc0ae08",
   "metadata": {},
   "source": [
    "* CLAHE: Contrast Limited Adaptive Histogram Equalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2755056-e275-4b78-b583-4dc4c33317bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_clahe_rgb(img, clipLimit=2, tileGridSize=(10, 10)):\n",
    "    # LAB color model where L = Lightness, a = green-red, b = blue-yellow\n",
    "    light, a, b = cv2.split(cv2.cvtColor(img, cv2.COLOR_BGR2LAB)) # convert to LAB color model\n",
    "    light_clahe = cv2.createCLAHE(clipLimit=clipLimit, tileGridSize=tileGridSize).apply(light) # apply CLAHE for lightness (L) component only\n",
    "    return cv2.cvtColor(cv2.merge((light_clahe, a, b)), cv2.COLOR_LAB2BGR) # return with reconvert to BGR color model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20dc7eb-cb67-4f43-9a32-a08d0f524c93",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "71576fc8-16e2-480d-a9f8-6fbc0b3a3c45",
   "metadata": {},
   "source": [
    "### 3. Edge Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0598910e-6532-4a8f-a08d-8ff284402536",
   "metadata": {},
   "source": [
    "* High-pass Filter\n",
    "\n",
    "`REMEMBER` To perform edge detection, the image should be in **grayscale** format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f761effc-6ddc-456c-acb3-b31024781917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb67f42-72e2-460f-ae11-599e442f8a37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d7d7f042-e9a1-4a9c-a513-6747fc1eec22",
   "metadata": {},
   "source": [
    "### 4. Image Transformation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fddced9-3a9e-439d-82b2-1cd701f26cfe",
   "metadata": {},
   "source": [
    "* Resizing (Interpolation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d64a7b82-877b-4395-aa8e-b258db4944f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2899dd54-001b-4deb-a321-955afc63db43",
   "metadata": {},
   "source": [
    "## CHALLENGE<br>Try other interpolation techniques:<br>  -> cv2.INTER_LINEAR<br>  -> cv2.INTER_CUBIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f48997d-adb2-4a21-9dde-7eb557fe9b6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
